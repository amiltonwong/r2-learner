{
 "metadata": {
  "name": "",
  "signature": "sha256:b695136ce6cc0f04dccb7104155cbb1ae0783a666591e736c559fdc3f87c219a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "x = np.array([[1,2,3,4],[3,4,5,6]])\n",
      "y = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
      "\n",
      "def foo(x,y):\n",
      "    r = np.sqrt(np.sum((x-y)**2, axis=1))\n",
      "    return np.exp(-(0.1*r)**2)\n",
      "\n",
      "print x[0]\n",
      "\n",
      "[ foo(x[i], y) for i in range(x.shape[0])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "liver = datasets.fetch_mldata('liver-disorders')\n",
      "print set(liver.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "from sklearn import svm, datasets\n",
      "from sklearn.grid_search import ParameterGrid, GridSearchCV\n",
      "from sklearn.base import BaseEstimator, clone \n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "import os\n",
      "import math\n",
      "import numpy as np\n",
      "import seaborn\n",
      "import sklearn.metrics\n",
      "from multiprocessing import Pool\n",
      "from models import *\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_moon, Y_moon = sklearn.datasets.make_moons(n_samples=1000, noise=0.04)\n",
      "X_spiral, Y_spiral = np.loadtxt(\"data/two_spirals.x\", skiprows=1), np.loadtxt(\"data/two_spirals.y\", skiprows=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#TODO: fit C\n",
      "class R2SVMLearner(BaseEstimator): \n",
      "    def __init__(self, kernel='linear', C=1, \\\n",
      "                 activation='sigmoid', recurrent=True, \\\n",
      "                 depth=7, seed=None, beta=0.1, scale=False,\n",
      "                 use_prev = False, jobs=-1):\n",
      "        \n",
      "        self.use_prev = use_prev\n",
      "        self.depth = depth\n",
      "        self.beta = beta\n",
      "        self.base_cls = partial(svm.SVC, class_weight='auto', kernel='linear', C=C)\n",
      "        self.seed = seed\n",
      "        self.scale = scale\n",
      "        self.activation = activation\n",
      "        self.recurrent = recurrent\n",
      "        self.C = C\n",
      "        self.jobs = jobs\n",
      "        self.X_tr = []\n",
      "        self.layer_coefs_ = []\n",
      "        self.layer_scores_ = []\n",
      "        \n",
      "        if activation == 'tanh': \n",
      "            self.activation = lambda x: 2./(1.+np.exp(x)) - 1.\n",
      "        elif activation == 'sigmoid':\n",
      "            self.activation = lambda x: 1.0/(1.0 + np.exp(-x))\n",
      "        else:\n",
      "            self.activation = activation\n",
      "    \n",
      "    def fit(self, X, Y):\n",
      "        self.K = len(set(Y)) # Class number\n",
      "        \n",
      "        # Seed\n",
      "        if self.seed is None: self.seed = np.random.randint(0, np.iinfo(np.int32).max)\n",
      "        self.random_state = np.random.RandomState(self.seed)\n",
      "        \n",
      "        # Models and scalers\n",
      "        self.scalers_ = [MinMaxScaler() for _ in xrange(self.depth)]\n",
      "        if self.K <= 2:\n",
      "            self.models_ = [self.base_cls() for _ in xrange(self.depth)]\n",
      "            for m in self.models_:\n",
      "                m.set_params(random_state=self.random_state)\n",
      "        else :\n",
      "            self.models_ = [OneVsRestClassifier(self.base_cls().set_params(random_state=self.random_state), n_jobs=self.jobs) for _ in xrange(self.depth)]\n",
      "            \n",
      "        # Prepare data\n",
      "        X_mod = X\n",
      "        o = []\n",
      "        delta = np.zeros(shape=X.shape)\n",
      "        self.W = []\n",
      "        self.X_tr = [X_mod]\n",
      "        \n",
      "        # Fit\n",
      "        for i in xrange(self.depth):\n",
      "            X_mod = self.scalers_[i].fit_transform(X_mod) if self.scale else X_mod\n",
      "            self.models_[i].fit(X_mod, Y)\n",
      " \n",
      "            o.append(self.models_[i].decision_function(X_mod) if self.K > 2 else \\\n",
      "                np.hstack([-self.models_[i].decision_function(X_mod), self.models_[i].decision_function(X_mod)]))\n",
      "            \n",
      "            self.W.append(self.random_state.normal(size=(self.K, X.shape[1])))\n",
      "            \n",
      "            if self.recurrent:\n",
      "                delta += np.dot(o[i], self.W[i])\n",
      "            else:\n",
      "                raise NotImplementedError()\n",
      " \n",
      "            if self.use_prev:\n",
      "                X_mod = self.activation(X_mod + self.beta*delta)\n",
      "            else:\n",
      "                X_mod = self.activation((self.scalers_[0].transform(X) if self.scale else X) + self.beta*delta)\n",
      "                  \n",
      "            self.X_tr.append(X_mod)\n",
      "            \n",
      "        return self\n",
      "    \n",
      "    def predict(self, X):\n",
      "        # Prepare data\n",
      "        X_mod = X\n",
      "        o = []\n",
      "        delta = np.zeros(shape=X.shape)\n",
      "        \n",
      "        for i in xrange(self.depth-1):\n",
      "            X_mod = self.scalers_[i].transform(X_mod) if self.scale else X_mod\n",
      "            \n",
      "            o.append(self.models_[i].decision_function(X_mod) if self.K > 2 else \\\n",
      "                np.hstack([-self.models_[i].decision_function(X_mod), self.models_[i].decision_function(X_mod)]))\n",
      "            \n",
      "            if self.recurrent:\n",
      "                delta += np.dot(o[i], self.W[i])\n",
      "            else:\n",
      "                raise NotImplementedError()            \n",
      "        \n",
      "            if not self.use_prev:\n",
      "                X_mod = self.activation((self.scalers_[0].transform(X) if self.scale else X) + self.beta*delta)\n",
      "            else:\n",
      "                X_mod = self.activation(X_mod + self.beta*delta)\n",
      "            \n",
      "        X_mod = self.scalers_[self.depth-1].transform(X_mod) if self.scale else X_mod\n",
      "        \n",
      "        return self.models_[-1].predict(X_mod)\n",
      "    \n",
      "    def fit_predict(self, X, Y, score_func=sklearn.metrics.accuracy_score):\n",
      "        self.K = len(set(Y)) # Class number\n",
      "        \n",
      "        # Seed\n",
      "        if self.seed is None: self.seed = np.random.randint(0, np.iinfo(np.int32).max)\n",
      "        self.random_state = np.random.RandomState(self.seed)\n",
      "        \n",
      "        # Models and scalers\n",
      "        self.scalers_ = [MinMaxScaler() for _ in xrange(self.depth)]\n",
      "        if self.K <= 2:\n",
      "            self.models_ = [self.base_cls() for _ in xrange(self.depth)]\n",
      "            for m in self.models_:\n",
      "                m.set_params(random_state=self.random_state)\n",
      "        else :\n",
      "            self.models_ = [OneVsRestClassifier(self.base_cls().set_params(random_state=self.random_state), n_jobs=self.jobs) for _ in xrange(self.depth)]\n",
      "            \n",
      "        # Prepare data\n",
      "        X_mod = X\n",
      "        o = []\n",
      "        delta = np.zeros(shape=X.shape)\n",
      "        self.W = []\n",
      "        self.X_tr.append(X_mod)\n",
      "        self.layer_coefs_ = []\n",
      "        self.layer_scores_ = []\n",
      "        \n",
      "        # Fit\n",
      "        for i in xrange(self.depth):\n",
      "            X_mod = self.scalers_[i].fit_transform(X_mod) if self.scale else X_mod\n",
      "            self.models_[i].fit(X_mod, Y)\n",
      "            \n",
      "            self.layer_scores_.append(score_func(Y, self.models_[i].predict(X_mod)))\n",
      "            self.layer_coefs_.append(self.models_[i].coef_)\n",
      " \n",
      "            o.append(self.models_[i].decision_function(X_mod) if self.K > 2 else \\\n",
      "                np.hstack([-self.models_[i].decision_function(X_mod), self.models_[i].decision_function(X_mod)]))\n",
      "            \n",
      "            self.W.append(self.random_state.normal(size=(self.K, X.shape[1])))\n",
      "            \n",
      "            if self.recurrent:\n",
      "                delta += np.dot(o[i], self.W[i])\n",
      "            else:\n",
      "                raise NotImplementedError()\n",
      " \n",
      "            if self.use_prev:\n",
      "                X_mod = self.activation(X_mod + self.beta*delta)\n",
      "            else:\n",
      "                X_mod = self.activation((self.scalers_[0].transform(X) if self.scale else X) + self.beta*delta)\n",
      "                  \n",
      "            self.X_tr.append(X_mod)\n",
      "            \n",
      "        return self\n",
      "    \n",
      "    def score(self, X, Y):\n",
      "        return sklearn.metrics.accuracy_score(Y, self.predict(X))\n",
      "        \n",
      "                    \n",
      "                        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def grid_search(param_grid, X, Y, model=R2SVMLearner, cv=3, max_iter=10, min_variance=0.15, verbose=True):\n",
      "    \n",
      "    grid_params = list(ParameterGrid(param_grid))\n",
      "    scores = []\n",
      "    params = []\n",
      "    min_iter = max_iter/4\n",
      "    \n",
      "    def run(param) :\n",
      "        score = 0.\n",
      "        folds = KFold(len(X), cv, shuffle=True)\n",
      "        for train_index, test_index in folds:\n",
      "            temp_model = model(**param).fit(X[train_index], Y[train_index])\n",
      "            score += sklearn.metrics.accuracy_score(Y[test_index], temp_model.predict(X[test_index]))\n",
      "            \n",
      "        return str(param), score/float(cv)\n",
      "     \n",
      "    for j, param in enumerate(grid_params) :\n",
      "        p, s = run(param)\n",
      "        params.append(p)\n",
      "        scores.append(s)\n",
      "        \n",
      "#         t_scores = []\n",
      "#         for i in xrange(max_iter):\n",
      "#             # print \"%i/%i - %i/%i\" % (j, len(grid_params)-1, i, max_iter-1)\n",
      "#             p, s = run(param)\n",
      "#             t_scores.append(s)\n",
      "#             if i > min_iter and np.std(t_scores) <= min_variance :\n",
      "#                 params.append(p)\n",
      "#                 scores.append(s)\n",
      "#                 break\n",
      "#             if i == max_iter - 1 and verbose:\n",
      "#                 print \"No convergence for %s %i/%i\" % (str(param), j, len(grid_params))\n",
      "#                 print \"Score variance:\", np.std(t_scores)\n",
      "\n",
      "    return params, scores\n",
      "\n",
      "X, Y = X_moon, Y_moon\n",
      "param_grid = {'depth': [5], 'beta': [0.1, 0.2]}\n",
      "\n",
      "params, scores = grid_search(param_grid, X, Y)\n",
      "print params[np.argmax(scores)], np.max(scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = heart_x, heart_y\n",
      "model = R2SVMLearner()\n",
      "param_grid = {'beta': [0.1], 'C': [1,10,100], 'scale': [True]}\n",
      "grid = GridSearchCV(model, param_grid)\n",
      "grid.fit(X, Y)\n",
      "print grid.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = heart_x, heart_y\n",
      "model = R2SVMLearner(depth=3, C=1)\n",
      "model.fit_predict(X,Y)\n",
      "print model.layer_scores_\n",
      "print len(model.layer_coefs_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load MNIST\n",
      "import cPickle, gzip\n",
      "f = gzip.open('mnist.pkl.gz', 'rb')\n",
      "train_set, valid_set, test_set = cPickle.load(f)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "heart_x, heart_y = datasets.load_svmlight_file('./data/heart')\n",
      "heart_x = heart_x.toarray()\n",
      "print heart_y[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris = datasets.load_iris()\n",
      "liver = datasets.fetch_mldata('liver-disorders')\n",
      "segment = datasets.fetch_mldata('segment')\n",
      "satimage = datasets.fetch_mldata('satimage')\n",
      "wine = datasets.fetch_mldata('uci-20070111 wine')\n",
      "\n",
      "iris['name'] = 'iris'\n",
      "liver['name'] = 'liver'\n",
      "segment['name'] = 'segment'\n",
      "satimage['name'] = 'satimage'\n",
      "wine['name'] = 'wine'\n",
      "\n",
      "uci_data_sets = [iris, liver, segment, satimage, wine] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "X = heart_x\n",
      "Y = heart_y\n",
      "\n",
      "params = {'k': [2,5], 'scale':[True], 'recurrent': [True]}\n",
      "our_params = {'depth': [2,5], 'beta': [0.04], 'C': [1], 'scale': [True] }\n",
      "\n",
      "p, s = grid_search(our_params, X, Y, model=R2SVMLearner)\n",
      "for a,b in zip(p,s) :\n",
      "    print a,b \n",
      "print\n",
      "\n",
      "p, s = grid_search(params, X, Y, model=R2Lin)\n",
      "for a,b in zip(p,s) :\n",
      "    print a,b \n",
      "print\n",
      "    \n",
      "param_grid_rbf = {'kernel': ['rbf'], 'C': [np.exp(10)], 'gamma': [np.exp(-12)]}\n",
      "p,s = grid_search(param_grid_rbf, X, Y, model=sklearn.svm.SVC)\n",
      "for a,b in zip(p,s) :\n",
      "    print a,b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fit_R2SVM(param_grid, )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "param_grid_our = {'depth': [2,5], 'beta': [0.1], 'cls_params': [{'C': c, 'kernel': 'linear'} for c in [1,10,100]]}\n",
      "param_grid_w = {'l': [2,5], 'beta': [0.1], 'C': [1,10,100]}\n",
      "param_grid_rbf = {'kernel': ['rbf'], 'C': [1,10,100], 'gamma': [0,1,10]}\n",
      "\n",
      "for data_set in uci_data_sets :\n",
      "    X = data_set.data\n",
      "    Y = data_set.target\n",
      "    params_our, scores_our = grid_search(param_grid_our, X, Y, model=R2SVMLearner)\n",
      "    params_w, scores_w = grid_search(param_grid_w, X, Y, model=R2SVM)\n",
      "    params_rbf, scores_rbf = grid_search(param_grid_rbf, X, Y, model=sklearn.svm.SVC)\n",
      "    \n",
      "    print \"R2SVMLearner on %s, dim: %i, #class: %i acc: %f\" % (data_set.name, X[0].shape[0], len(set(Y)), np.max(scores_our))\n",
      "    print \"R2SVM on %s, dim: %i, #class: %i acc: %f\" % (data_set.name, X[0].shape[0], len(set(Y)), np.max(scores_w))\n",
      "    print \"rbf SVM on %s, dim: %i, #class: %i acc: %f\" % (data_set.name, X[0].shape[0], len(set(Y)), np.max(scores_rbf))\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = wine.data, wine.target\n",
      "\n",
      "param_grid_our = {'depth': [2,5,10,30], 'beta': [0.1, 0.2], 'cls_params': [{'C': c, 'kernel': 'linear'} for c in [1,10,100]]}\n",
      "params_our, scores_our = grid_search(param_grid_our, X, Y, model=R2SVMLearner)\n",
      "print params_our[np.argmax(scores_our)], np.max(scores_our)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = wine.data, wine.target\n",
      "\n",
      "param_grid_w = {'l': [2,5,10,30], 'beta': [0.1, 0.2], 'C': [1,10,100]}\n",
      "params_w, scores_w = grid_search(param_grid_w, X, Y, model=R2SVM)\n",
      "print params_w[np.argmax(scores_w)], np.max(scores_w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = wine.data, wine.target\n",
      "param_grid_rbf = {'kernel': ['rbf'], 'C': [1,10,100], 'gamma': [0,1,10,100]}\n",
      "params_rbf, scores_rbf = grid_search(param_grid_rbf, X, Y, model=sklearn.svm.SVC)\n",
      "print params_rbf[np.argmax(scores_rbf)], np.max(scores_rbf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = wine.data, wine.target\n",
      "param_grid_rbf = {'kernel': ['rbf'], 'C': [1,10,100], 'gamma': [0,1,10,100]}\n",
      "params_rbf, scores_rbf = grid_search(param_grid_rbf, X, Y, model=sklearn.svm.SVC)\n",
      "print params_rbf[np.argmax(scores_rbf)], np.max(scores_rbf)\n",
      "\n",
      "rbf = sklearn.svm.SVC()\n",
      "grid = GridSearchCV(rbf, param_grid_rbf, scoring='accuracy')\n",
      "grid.fit(X,Y)\n",
      "print grid.best_params_, grid.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = X_moon, Y_moon\n",
      "model = R2SVMLearner(depth=10, beta=0.1, C=1)\n",
      "model.fit(X, Y)\n",
      "\n",
      "%matplotlib inline\n",
      "import matplotlib.pylab as plt\n",
      "plt.scatter(model.X_tr[-1][:,0], model.X_tr[-1][:,1], c=Y)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 300\n",
      "x, y = np.linspace(X.min(), X.max(), N),  np.linspace(X.min(), X.max(), N)\n",
      "xx, yy = np.meshgrid(x, y)\n",
      "z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "# z = model._feed_forward(np.c_[xx.ravel(), yy.ravel()])[:,0]\n",
      "plt.contourf(xx, yy, z.reshape(N,N), cmap=plt.cm.Paired, alpha=0.8)\n",
      "plt.scatter(X[:,0], X[:,1], c=Y,  cmap=plt.cm.Paired, alpha=0.8)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = X_moon, Y_moon\n",
      "model = R2Lin(k=5)\n",
      "model.fit(X, Y)\n",
      "N = 300\n",
      "x, y = np.linspace(X.min(), X.max(), N),  np.linspace(X.min(), X.max(), N)\n",
      "xx, yy = np.meshgrid(x, y)\n",
      "z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "# z = model._feed_forward(np.c_[xx.ravel(), yy.ravel()])[:,0]\n",
      "plt.contourf(xx, yy, z.reshape(N,N), cmap=plt.cm.Paired, alpha=0.8)\n",
      "plt.scatter(X[:,0], X[:,1], c=Y,  cmap=plt.cm.Paired, alpha=0.8)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_and_plot(X, Y, **R2_params):\n",
      "    plot_side = int(math.sqrt(R2_params['depth']))\n",
      "    if plot_side**2 < R2_params['depth']: plot_side += 1\n",
      "\n",
      "    for i in range(R2_params['depth']):\n",
      "        model = R2SVMLearner(**R2_params)\n",
      "        model.fit(X, Y)\n",
      "        \n",
      "        plt.subplot(plot_side, plot_side, i + 1)\n",
      "        \n",
      "        N = 200\n",
      "\n",
      "        x, y = np.linspace(X.min(), X.max(), N),  np.linspace(X.min(), X.max(), N)\n",
      "        xx, yy = np.meshgrid(x, y)\n",
      "        z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "        plt.contourf(xx, yy, z.reshape(N,N), cmap=plt.cm.Paired, alpha=0.8)\n",
      "        plt.scatter(X[:,0], X[:,1], c=Y,  cmap=plt.cm.Paired, alpha=0.8)\n",
      "        plt.show()\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run_and_plot(X_moon, Y_moon, beta=0.1, depth=5, C=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = X_moon, Y_moon\n",
      "model3 = R2SVM(l=2)\n",
      "model3.fit(X, Y)\n",
      "print model3.score(X, Y)\n",
      "model3.drawdata(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 300\n",
      "x, y = np.linspace(X.min(), X.max(), N),  np.linspace(X.min(), X.max(), N)\n",
      "xx, yy = np.meshgrid(x, y)\n",
      "z = np.array(model3.predict(np.c_[xx.ravel(), yy.ravel()]))\n",
      "# z = model._feed_forward(np.c_[xx.ravel(), yy.ravel()])[:,0]\n",
      "plt.contourf(xx, yy, z.reshape(N,N), cmap=plt.cm.Paired, alpha=0.8)\n",
      "plt.scatter(X[:,0], X[:,1], c=Y,  cmap=plt.cm.Paired, alpha=0.8)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "from scipy.sparse import vstack\n",
      "import os\n",
      "data_dir = '../data'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pen_train_x, pen_train_y, pen_test_x, pen_test_y = datasets.load_svmlight_files((os.path.join(data_dir, 'pendigits'),\n",
      "                                                                                     os.path.join(data_dir, 'pendigits.t')))\n",
      "print pen_train_x.shape\n",
      "print pen_test_x.shape\n",
      "\n",
      "pen_x = vstack([pen_train_x, pen_test_x])\n",
      "pen_y = np.hstack([pen_train_y, pen_test_y])\n",
      "\n",
      "print pen_x.shape\n",
      "print pen_y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news_train_x, news_train_y, news_test_x, news_test_y = datasets.load_svmlight_files((os.path.join(data_dir, 'news20.scale'),\n",
      "                                                                                     os.path.join(data_dir, 'news20.t.scale')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print news_test_x.shape\n",
      "print news_test_y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print news_train_x.shape\n",
      "print news_train_y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news_x = vstack([news_train_x, news_test_x])\n",
      "news_y = np.hstack([news_train_y, news_test_y])\n",
      "print news_x.shape\n",
      "print news_y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(news_test_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "covtype = datasets.fetch_covtype()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('../data/mnist.pkl')\n",
      "train_set, valid_set, test_set = pickle.load(f)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnist_x = np.vstack([train_set[0], valid_set[0], test_set[0]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnist_x.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set[0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mnist_y = np.hstack([train_set[1], valid_set[1], test_set[1]])\n",
      "print mnist_y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.path.append('..')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "from data_api import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "small = fetch_small_datasets()\n",
      "large = fetch_large_datasets()\n",
      "binary = fetch_binray_datasets()\n",
      "fmedium = fetch_medium_datasets()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fmedium[0].data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}