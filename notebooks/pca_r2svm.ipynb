{
 "metadata": {
  "name": "",
  "signature": "sha256:836f83d0b1f58e40171a8f5cee49d222782ca1f0f4e3026d484a0e6b6bf50b08"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Trying out pca r2svm if has competitive performance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import sys\n",
      "import os\n",
      "sys.path.append(\"..\")\n",
      "\n",
      "from sklearn import svm, datasets\n",
      "from sklearn.grid_search import ParameterGrid, GridSearchCV\n",
      "from sklearn.base import BaseEstimator, clone \n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.svm import SVC\n",
      "import os\n",
      "import math\n",
      "import numpy as np\n",
      "import sklearn.metrics\n",
      "from multiprocessing import Pool\n",
      "from functools import partial\n",
      "\n",
      "import sklearn\n",
      "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "\n",
      "from data_api import *\n",
      "\n",
      "from r2 import *\n",
      "\n",
      "\n",
      "from misc.config import c\n",
      "from data_api import *\n",
      "import cPickle\n",
      "import pandas as pd\n",
      "from data_api import *\n",
      "results_dir = c['RESULTS_DIR']\n",
      "\n",
      "from scripts.fit_models import *\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "glass = fetch_uci_datasets([\"glass\"])[0]\n",
      "X, Y = glass.data, glass.target\n",
      "assert(sklearn.metrics.accuracy_score(R2SVMLearner(seed=3, beta=0.8).fit(X, Y).predict(X), Y) == sklearn.metrics.accuracy_score(R2SVMLearner(seed=3, beta=0.8).fit(X, Y).predict(X), Y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "diabetes_exp = cPickle.load(open(os.path.join(results_dir, \n",
      "                                           'unit_test_r2svm_diabetes', \n",
      "                                           'unit_test_r2svm_diabetes_uT_rT_b0.10_d10_sT_fra_.experiment')))\n",
      "diabetes_params = diabetes_exp['config']['params']\n",
      "print diabetes_params\n",
      "\n",
      "indian_exp = cPickle.load(open(os.path.join(results_dir, \n",
      "                                           'unit_test_r2svm_indian', \n",
      "                                           'unit_test_r2svm_indian_uF_rT_b1.00_d10_sF_fra_.experiment')))\n",
      "indian_params = indian_exp['config']['params']\n",
      "print indian_params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'use_prev': True, 'recurrent': True, 'beta': 0.1, 'depth': 10, 'scale': True, 'fit_c': 'random', 'seed': 666}\n",
        "{'use_prev': False, 'recurrent': True, 'beta': 1.0, 'depth': 10, 'scale': False, 'fit_c': 'random', 'seed': 666}\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indians = fetch_uci_datasets(['indian'])[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from r2 import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indian_params_random = dict(indian_params)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indian_params_random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "{'beta': 1.0,\n",
        " 'depth': 10,\n",
        " 'fit_c': 'random_cls',\n",
        " 'recurrent': True,\n",
        " 'scale': False,\n",
        " 'seed': 666,\n",
        " 'use_prev': False}"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set(indians.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 162,
       "text": [
        "{1.0, 2.0}"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indians.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 170,
       "text": [
        "(583, 10)"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indian_params_random['fit_c'] = 'random_cls_centered'\n",
      "indian_params_random['use_prev'] = True\n",
      "indian_params_random['recurrent'] = False\n",
      "indian_params_random['depth'] = 4\n",
      "indian_params_random['random_hyperplanes'] = 6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_fold(R2SVMLearner, params=indian_params_random, seed=666, data=indians, exp_name=\"check_cons\", model_name=\"r2svm\", save_model=False)['results']['mean_acc']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 215,
       "text": [
        "0.5991080839415146"
       ]
      }
     ],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_fold(R2SVMLearner, params=indian_params, seed=666, data=indians, exp_name=\"check_cons\", model_name=\"r2svm\", save_model=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 135,
       "text": [
        "{'config': {'experiment_name': 'check_cons_r2svm_indian_uF_rT_b1.00_d10_sF_fra_',\n",
        "  'n_folds': 5,\n",
        "  'params': {'beta': 1.0,\n",
        "   'depth': 10,\n",
        "   'fit_c': 'random',\n",
        "   'recurrent': True,\n",
        "   'scale': False,\n",
        "   'seed': 666,\n",
        "   'use_prev': False},\n",
        "  'seed': 666,\n",
        "  'store_clf': False},\n",
        " 'monitors': {'acc_fold': array([[ 0.71186441,  0.72033898,  0.72033898],\n",
        "         [ 0.71794872,  0.75213675,  0.73504274],\n",
        "         [ 0.72413793,  0.72413793,  0.71551724],\n",
        "         [ 0.71551724,  0.71551724,  0.71551724],\n",
        "         [ 0.71551724,  0.71551724,  0.71551724]]),\n",
        "  'best_depth': [8, 5, 1, 3, 6],\n",
        "  'clf': [],\n",
        "  'data_name': 'indian',\n",
        "  'n_class': 2,\n",
        "  'n_dim': 10,\n",
        "  'std': 0.0099680965711943428,\n",
        "  'test_time': [[0.0050890445709228516,\n",
        "    0.005107879638671875,\n",
        "    0.0047910213470458984],\n",
        "   [0.0051059722900390625, 0.0048711299896240234, 0.005081892013549805],\n",
        "   [0.0050389766693115234, 0.005028963088989258, 0.00516200065612793],\n",
        "   [0.00503087043762207, 0.00507807731628418, 0.005046844482421875],\n",
        "   [0.005017995834350586, 0.00506281852722168, 0.004836082458496094]],\n",
        "  'train_time': [[0.8143830299377441, 1.024778127670288, 1.0964138507843018],\n",
        "   [0.952812910079956, 1.010181188583374, 0.9743039608001709],\n",
        "   [0.9547550678253174, 0.8880641460418701, 0.8871011734008789],\n",
        "   [0.9379520416259766, 0.9250650405883789, 1.063655138015747],\n",
        "   [0.9305109977722168, 1.0310561656951904, 0.8338329792022705]]},\n",
        " 'results': {'mean_acc': 0.72097114198224643}}"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 138,
       "text": [
        "0.34293360707738257"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy\n",
      "\n",
      "import sklearn\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
      "from sklearn.multiclass import OneVsRestClassifier\n",
      "from sklearn.cross_validation import KFold, cross_val_score\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "from functools import partial\n",
      "from elm import ELM\n",
      "\n",
      "from sklearn.base import BaseEstimator, clone\n",
      "\n",
      "\n",
      "class MyLinModel(BaseEstimator):\n",
      "    def __init__(self,w,b):\n",
      "        assert isinstance(b, (int, long, float)) or len(b.shape) == 1\n",
      "        self.w=w\n",
      "        self.b=b\n",
      "\n",
      "    def fit(self, X, Y):\n",
      "        pass\n",
      "\n",
      "    def predict(self, X):\n",
      "        return np.argmax(self.decision_function(X), axis=1)\n",
      "\n",
      "    def decision_function(self, X):\n",
      "        return X.dot(self.w.T) + self.b\n",
      "\n",
      "def make_rand_vector(dims):\n",
      "    vec = [np.random.normal(0, 1) for i in range(dims)]\n",
      "    mag = sum(x**2 for x in vec) ** .5\n",
      "    return np.array([[x/mag for x in vec]])\n",
      "\n",
      "\n",
      "def _r2_compress_model(r2):\n",
      "    \"\"\"\n",
      "    If models are LinearMixins <=> have coefs_ and coef0_ it rewrites to dicts (nope, idk why)//those to MyLinModel. It is still functional model :)\n",
      "    \"\"\"\n",
      "    # #\n",
      "    #MyLinModel(r2.models_[id].coef_, r2.models_[id].intercept_)\n",
      "    r2._X_tr = []\n",
      "    r2._X_moved = []\n",
      "    r2.X_tr = []\n",
      "    for id, m in enumerate(r2.models_):\n",
      "        # I know it should be class testing ok?\n",
      "        if hasattr(r2.models_[id], 'coef_'):\n",
      "            if hasattr(r2.models_[id], 'intercept_'):\n",
      "                r2.models_[id] = {\"w\": r2.models_[id].coef_, \"b\":  r2.models_[id].intercept_, \"params\": r2.models_[id].get_params()}\n",
      "            elif hasattr(r2.models_[id], 'coef0'):\n",
      "                r2.models_[id] = {\"w\": r2.models_[id].coef_, \"b\":  r2.models_[id].coef0, \"params\": r2.models_[id].get_params()}\n",
      "    return r2\n",
      "\n",
      "class R2Learner(BaseEstimator):\n",
      "    def __init__(self, C=1, activation='sigmoid', recurrent=True, depth=7, \\\n",
      "                 seed=None, beta=0.1, scale=False, use_prev=False, fit_c=None, base_cls=None,\n",
      "\t\t\t\tfixed_prediction=False, is_base_multiclass=False, switched=False, random_hyperplanes=None):\n",
      "        self.name = 'r2svm'\n",
      "        self.fixed_prediction = fixed_prediction\n",
      "        self.use_prev = use_prev\n",
      "        self.fit_c = fit_c\n",
      "        self.depth = depth\n",
      "        self.beta = beta\n",
      "        self.base_cls = base_cls\n",
      "        self.seed = seed\n",
      "        self.scale = scale\n",
      "        self.recurrent = recurrent\n",
      "        self.C = C\n",
      "        self.X_tr = []\n",
      "        self.layer_predictions_ = []\n",
      "        self.activation = activation  # Minor hack to pickle functions, we will call it by getattr\n",
      "        self.is_base_multiclass = is_base_multiclass  # Minor hack to know when to wrap in OneVsRest\n",
      "        self.random_hyperplanes = random_hyperplanes\n",
      "        \n",
      "        # Used in _feed_forward for keeping state\n",
      "        self._o = []\n",
      "        self._delta = []\n",
      "        self._fitted = False\n",
      "        self._X_moved = []\n",
      "        self._X_tr = []\n",
      "        self._prev_C = None\n",
      "        self.switched = switched\n",
      "\n",
      "\n",
      "    def _feed_forward(self, X, i, Y=None):\n",
      "        # Modifies state (_o, _delta, _fitted, _X_tr, _X_moved)\n",
      "        # Assumes scaled data passed to it (so you have to scale data)\n",
      "\n",
      "        if i == 0:\n",
      "            self._o = []\n",
      "            self._delta = np.zeros(shape=X.shape)\n",
      "            self._X_tr = [X]\n",
      "            self._X_moved = [X]\n",
      "\n",
      "        if not self._fitted:\n",
      "            if self.fit_c is None:\n",
      "                self.models_[i].fit(X, Y)\n",
      "            elif self.fit_c == 'random_cls' or self.fit_c == 'random_cls_centered':\n",
      "                if i != self.depth - 1:\n",
      "                    if self.K <= 2:\n",
      "                        w = make_rand_vector(X.shape[1])\n",
      "                        if self.fit_c == 'random_cls':\n",
      "                            b = np.random.uniform(X.min(), X.max())\n",
      "                        elif self.fit_c == 'random_cls_centered':\n",
      "                            p = w.dot(X.T)\n",
      "                            if np.std(p) != 0:\n",
      "                                b = np.random.normal(p.mean(), np.std(p)*2)\n",
      "                            else:\n",
      "                                b = np.random.normal(p.mean(), 1)\n",
      "\n",
      "                        self.models_[i] = MyLinModel(w, b)\n",
      "                    else:\n",
      "                        w = np.hstack([make_rand_vector(X.shape[1]).T for _ in range(self.K)]).T\n",
      "                        p = w.dot(X.T)\n",
      "\n",
      "                        if self.fit_c == 'random_cls':\n",
      "                            b = np.array([np.random.uniform(X.min(), X.max()) for _ in range(self.K)])\n",
      "                        elif self.fit_c == 'random_cls_centered':\n",
      "                            b = []\n",
      "                            for pi in p:\n",
      "                                b.append(np.random.normal(pi.mean(), np.std(pi)*2))\n",
      "                            b = np.array(b)\n",
      "\n",
      "                        self.models_[i] = MyLinModel(w, b)\n",
      "                else:\n",
      "                    self.models_[i].fit(X, Y)\n",
      "            elif self.fit_c == 'random':\n",
      "                if not self.fixed_prediction or i == self.depth - 1:\n",
      "                    best_C = None\n",
      "                    best_score = 0.\n",
      "                    fit_size = 4\n",
      "                    if type(self.models_[i]) == ELM:\n",
      "                        c = [10**j for j in xrange(0, fit_size)]\n",
      "                    elif type(self.models_[i]) == LinearSVC or type(self.models_[i] == SVC) :\n",
      "                        c = np.random.uniform(size=fit_size)\n",
      "                        c = MinMaxScaler((-2, 8)).fit_transform(c)\n",
      "                        c = [np.exp(x) for x in c]\n",
      "                        # Add one and previous\n",
      "                        c = list(set(c).union([1]).union([self._prev_C])) if self._prev_C else list(set(c).union([1]))\n",
      "\n",
      "                    for j in xrange(fit_size):\n",
      "                        model = clone(self.models_[i]).set_params(estimator__C=c[j]) if not self.is_base_multiclass \\\n",
      "                                                                                        and self.K > 2 else \\\n",
      "                            clone(self.models_[i]).set_params(C=c[j])\n",
      "                        score = sklearn.metrics.accuracy_score(model.fit(X,Y).predict(X), Y)\n",
      "                        #scores = cross_val_score(model, X, Y, scoring='accuracy', \\\n",
      "                        #                         cv=KFold(X.shape[0], shuffle=True, random_state=self.random_state))\n",
      "                        #score = scores.mean()\n",
      "                        if score > best_score:\n",
      "                            best_score = score\n",
      "                            best_C = c[j]\n",
      "                    assert best_C is not None\n",
      "                    self.models_[i].set_params(estimator__C=best_C) if not self.is_base_multiclass and self.K > 2 \\\n",
      "                        else self.models_[i].set_params(C=best_C)\n",
      "                    self._prev_C = best_C\n",
      "                    self.models_[i].fit(X, Y)\n",
      "\n",
      "        if i != self.depth - 1:\n",
      "\n",
      "            if not self.fixed_prediction:\n",
      "                self._o.append(self.models_[i].decision_function(X) if self.K > 2 else \\\n",
      "\t\t                           np.vstack([-self.models_[i].decision_function(X).reshape(1, -1),\n",
      "\t\t                                      self.models_[i].decision_function(X).reshape(1, -1)]).T)\n",
      "            elif isinstance(self.fixed_prediction, (int, long, float, complex)):\n",
      "                self._o.append(np.ones(shape=(X.shape[0], self.K)) * self.fixed_prediction)\n",
      "            else:\n",
      "                raise NotImplementedError(\"self.fixed_prediction is wut?\")\n",
      "\n",
      "            if self.recurrent:\n",
      "                self._delta = sum(np.dot(self._o[j], self.W[i][j]) for j in range(i+1))\n",
      "            else:\n",
      "                self._delta = np.dot(self._o[i], self.W[i])\n",
      "\n",
      "            if self.use_prev:\n",
      "                self._X_moved.append(X + self.beta * self._delta)\n",
      "                X = getattr(self, \"_\" + self.activation)(self._X_moved[-1])\n",
      "            else:\n",
      "                self._X_moved.append(self._X_tr[0] + self.beta * self._delta)\n",
      "                X = getattr(self, \"_\" + self.activation)(self._X_moved[-1])\n",
      "\n",
      "            if self.scale:\n",
      "                if not self._fitted:\n",
      "                    X = self.scalers_[i + 1].fit_transform(X)\n",
      "                else:\n",
      "                    X = self.scalers_[i + 1].transform(X)\n",
      "\n",
      "            self._X_tr.append(X)\n",
      "        else:\n",
      "            self._fitted = True\n",
      "\n",
      "        return X\n",
      "\n",
      "    def fit(self, X, Y, W=None):\n",
      "        \n",
      "        if self.random_hyperplanes:\n",
      "            self.K = random_hyperplanes\n",
      "        else:\n",
      "            self.K = len(set(Y))  # Class number\n",
      "            \n",
      "        # Seed\n",
      "        if self.seed is None:\n",
      "            self.seed = np.random.randint(0, np.iinfo(np.int32).max)\n",
      "        else:\n",
      "            np.random.seed(self.seed)\n",
      "            # print(\"WARNING: seeding whole numpy (forced by bug in SVC)\")\n",
      "        self.random_state = np.random.RandomState(self.seed)\n",
      "\n",
      "        # Models and scalers\n",
      "        self.scalers_ = [MinMaxScaler((-1, 1)) for _ in xrange(self.depth)]\n",
      "\n",
      "        if self.K <= 2:\n",
      "            self.models_ = [self.base_cls() for _ in xrange(self.depth)]\n",
      "            # for m in self.models_:\n",
      "            #    m.set_params(random_state=self.random_state)    # is this necessary?\n",
      "            # else :\n",
      "        else:\n",
      "            if self.is_base_multiclass:\n",
      "                if self.base_cls.func != LogisticRegression:\n",
      "                    self.models_ = [self.base_cls().set_params(random_state=self.random_state) for _ in xrange(self.depth)]\n",
      "                else:\n",
      "                    self.models_ = [self.base_cls() for _ in xrange(self.depth)]\n",
      "            else:\n",
      "                raise NotImplementedError, \"None base mutliclass models are deprecated.\"\n",
      "                # self.models_ = [OneVsRestClassifier(self.base_cls().set_params(random_state=self.random_state), \\\n",
      "                #                                     n_jobs=1) for _ in xrange(self.depth)]\n",
      "\n",
      "        if self.switched:\n",
      "            if self.base_cls.func != ELM:\n",
      "                raise NotImplementedError, \"Only switching from ELM to LinearSVC is supported\"\n",
      "            self.models_[-1] = LinearSVC( loss='l1', C=1, class_weight='auto', ).set_params(random_state=self.random_state)\n",
      "\n",
      "        if self.recurrent:\n",
      "            self.W = W if W else [[self.random_state.normal(size=(self.K, X.shape[1])) for _ in range(i+1)] \\\n",
      "                                  for i in range(self.depth - 1)]\n",
      "        else:\n",
      "            self.W = W if W else [self.random_state.normal(size=(self.K, X.shape[1])) for _ in range(self.depth - 1)]\n",
      "\n",
      "        # Prepare data\n",
      "        if self.scale:\n",
      "            X = self.scalers_[0].fit_transform(X)\n",
      "        self._fitted = False\n",
      "\n",
      "        # Fit\n",
      "        for i in xrange(self.depth):\n",
      "            X = self._feed_forward(X, i, Y)\n",
      "\n",
      "        return self\n",
      "\n",
      "    def predict(self, X, all_layers=False):\n",
      "        # Prepare data\n",
      "        if self.scale:\n",
      "            X = self.scalers_[0].transform(X)\n",
      "\n",
      "        _X = [X]\n",
      "        # Predict\n",
      "        for i in xrange(self.depth):\n",
      "            X = self._feed_forward(X, i)\n",
      "            if all_layers and i != self.depth-1: # Last layer is\n",
      "                _X.append(X)\n",
      "\n",
      "        if all_layers:\n",
      "            return [m.predict(X_tr) for m, X_tr in zip(self.models_, _X)]\n",
      "        else:\n",
      "            return self.models_[-1].predict(X)\n",
      "\n",
      "    @staticmethod\n",
      "    def _tanh(x):\n",
      "        return 2. / (1. + np.exp(x)) - 1.\n",
      "\n",
      "    @staticmethod\n",
      "    def _sigmoid(x):\n",
      "        return 1.0 / (1.0 + np.exp(-x))\n",
      "\n",
      "    @staticmethod\n",
      "    def _rbf(x):\n",
      "        return np.exp(-np.power((x - np.mean(x, axis=0)), 2))\n",
      "\n",
      "    @staticmethod\n",
      "    def _01_rbf(x):\n",
      "        return np.exp(-(np.power(x,2)/2))\n",
      "\n",
      "\n",
      "def score_all_depths_r2(model, X, Y):\n",
      "    \"\"\"\n",
      "    @returns depth, score_for_this_depth\n",
      "    \"\"\"\n",
      "    scores = [sklearn.metrics.accuracy_score(Y_pred, Y) for Y_pred in model.predict(X, all_layers=True)]\n",
      "    return np.argmax(scores)+1, scores[np.argmax(scores)]\n",
      "\n",
      "\n",
      "class R2ELMLearner(R2Learner):\n",
      "    def __init__(self, activation='sigmoid', recurrent=True, depth=10, \\\n",
      "                 seed=None, beta=0.1, scale=False, fit_c=None, use_prev=False, max_h=100, h=10,\n",
      "                 fit_h=None, C=100, fixed_prediction=False, switched=False):\n",
      "        \"\"\"\n",
      "        @param fixed_prediction pass float to fix prediction to this number or pass False to learn model\n",
      "        \"\"\"\n",
      "        self.h = h\n",
      "        self.max_h = max_h\n",
      "\n",
      "        if fit_h == None:\n",
      "            base_cls = partial(ELM, h=self.h, activation='linear', C=C)\n",
      "        else:\n",
      "            raise NotImplementedError()\n",
      "\n",
      "        R2Learner.__init__(self, fixed_prediction=fixed_prediction, activation=activation, recurrent=recurrent, depth=depth, \\\n",
      "                           seed=seed, beta=beta, scale=scale, use_prev=use_prev, base_cls=base_cls,\n",
      "                           is_base_multiclass=True, fit_c=fit_c, C=C, switched=switched)\n",
      "\n",
      "\n",
      "class R2SVMLearner(R2Learner):\n",
      "    def __init__(self, activation='sigmoid', recurrent=True, depth=10, seed=None, beta=0.1, scale=False,\n",
      "                 fixed_prediction=False, use_prev=False, fit_c=None, C=1, use_linear_svc=True, switched=False, random_hyperplanes=None):\n",
      "        \"\"\"\n",
      "        @param fixed_prediction pass float to fix prediction to this number or pass False to learn model\n",
      "        \"\"\"\n",
      "        if not use_linear_svc:\n",
      "            raise NotImplementedError(\"Deprecated. SVC seems much slower for it has to be wrapped as multiclass\")            \n",
      "\n",
      "            base_cls = partial(SVC, class_weight='auto', kernel='linear', C=C)\n",
      "\n",
      "            R2Learner.__init__(self, fixed_prediction=fixed_prediction, activation=activation, recurrent=recurrent, depth=depth, \\\n",
      "                               seed=seed, beta=beta, scale=scale, fit_c=fit_c, use_prev=use_prev, base_cls=base_cls,\n",
      "                               is_base_multiclass=False, random_hyperplanes=random_hyperplanes)\n",
      "        else:\n",
      "            base_cls = partial(LinearSVC, loss='l1', C=C, class_weight='auto')\n",
      "\n",
      "            R2Learner.__init__(self, fixed_prediction=fixed_prediction, activation=activation, recurrent=recurrent, depth=depth, \\\n",
      "                               seed=seed, beta=beta, fit_c=fit_c, scale=scale, use_prev=use_prev, base_cls=base_cls,\n",
      "                               is_base_multiclass=True, switched=switched)\n",
      "\n",
      "\n",
      "class R2LRLearner(R2Learner):\n",
      "    def __init__(self, activation='sigmoid', recurrent=True, depth=10, seed=None, beta=0.1, scale=False, \\\n",
      "                 fixed_prediction=False, use_prev=False, logger=None):\n",
      "\n",
      "        base_cls =  partial(LogisticRegression, fit_intercept=True)\n",
      "\n",
      "        R2Learner.__init__(self, fixed_prediction=fixed_prediction, activation=activation, recurrent=recurrent, depth=depth, \\\n",
      "                               seed=seed, beta=beta, scale=scale, use_prev=use_prev, base_cls=base_cls,\n",
      "                               is_base_multiclass=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 195
    }
   ],
   "metadata": {}
  }
 ]
}